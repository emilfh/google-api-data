{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "16ed06e8-3310-4b80-bd5f-d8a2c5cc02fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "import dateparser\n",
    "from datetime import date, timedelta\n",
    "\n",
    "# Import Modules\n",
    "import os.path\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "\n",
    "import sys\n",
    "# adding Notebooksfolder to the system path\n",
    "sys.path.insert(0, '/Users/emil/miniforge3/envs/googleapi/Notebooks')\n",
    "\n",
    "import importlib\n",
    "import dates_funcs\n",
    "importlib.reload(dates_funcs)\n",
    "from dates_funcs import appendDFToCSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "9b094ab9-d8db-4cf8-87e7-e64e4373f27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FRAN https://www.shortautomaton.com/connecting-to-google-search-console-api-with-python/ \n",
    "\n",
    "# Define function to get authorization\n",
    "def gsc_auth(scopes):\n",
    "    creds = None\n",
    "    # The file token.json stores the user's access and refresh tokens, and is\n",
    "    # created automatically when the authorization flow completes for the first\n",
    "    # time.\n",
    "    if os.path.exists('token.json'):\n",
    "        creds = Credentials.from_authorized_user_file('token.json', scopes)\n",
    "    # If there are no (valid) credentials available, let the user log in.\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                'client_secrets.json', scopes)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        # Save the credentials for the next run\n",
    "        with open('token.json', 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "\n",
    "    service = build('searchconsole', 'v1', credentials=creds)\n",
    "\n",
    "    return service\n",
    "\n",
    "scopes = ['https://www.googleapis.com/auth/webmasters.readonly']\n",
    "\n",
    "service = gsc_auth(scopes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc0b3d9-e288-4c3f-9cd2-9f5588db2e64",
   "metadata": {},
   "source": [
    "Query Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9465a9-8e22-4744-8fc7-bb482ef67999",
   "metadata": {},
   "source": [
    "Find latest Date in old CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "ada8d429-81e9-4867-9ada-3609f91a39c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last date saved: 2022-12-31\n"
     ]
    }
   ],
   "source": [
    "# Check of Dates\n",
    "f = open(\"latestDate.txt\")\n",
    "maxSavedDate = f.read()\n",
    "f.close()\n",
    "#print(\"Previously fetched data up to and including: \"+ maxSavedDate)\n",
    "maxSavedDateDT = datetime.datetime.strptime(maxSavedDate,'%Y-%m-%d').date()\n",
    "print(\"Last date saved: \"+maxSavedDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "e7455748-1a8a-42b2-b553-1fdfef632267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script started: 2023-06-14_15:06:33\n",
      "Fetching new data, starting: 2023-01-01\n",
      "up to and including: 2023-06-11\n"
     ]
    }
   ],
   "source": [
    "# Now to print to log when program running \n",
    "nowDT = datetime.datetime.now()\n",
    "now = datetime.datetime.strftime(nowDT,'%Y-%m-%d_%H:%M:%S')\n",
    "print(\"Script started: \"+now)\n",
    "\n",
    "# Check of Dates\n",
    "f = open(\"latestDate.txt\")\n",
    "maxSavedDate = f.read()\n",
    "f.close()\n",
    "# print(\"Previously fetched data up to and including: \"+ maxSavedDate)\n",
    "maxSavedDateDT = datetime.datetime.strptime(maxSavedDate,'%Y-%m-%d').date()\n",
    "\n",
    "# Todays date\n",
    "todayDT = date.today()\n",
    "today = datetime.datetime.strftime(todayDT,'%Y-%m-%d')\n",
    "\n",
    "# Three days ago to use as end date, since search console is not updated daily\n",
    "three_days_agoDT = todayDT + datetime.timedelta(days=-3)\n",
    "three_days_ago = datetime.datetime.strftime(three_days_agoDT,'%Y-%m-%d')\n",
    "\n",
    "# start_date as the next day as maxSavedDate\n",
    "test_start_dateDT = maxSavedDateDT + datetime.timedelta(days=1)\n",
    "test_start_date = datetime.datetime.strftime(test_start_dateDT,'%Y-%m-%d')\n",
    "print(\"Fetching new data, starting: \"+test_start_date)\n",
    "\n",
    "# test_end_dateDT = three days ago\n",
    "test_end_dateDT = three_days_agoDT\n",
    "test_end_date = datetime.datetime.strftime(test_end_dateDT,'%Y-%m-%d')\n",
    "\n",
    "print(\"up to and including: \"+test_end_date)\n",
    "\n",
    "start_date = test_start_date\n",
    "end_date = test_end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "cd882e7b-f73c-480d-8534-d9ef4ce4451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Dates with data available\n",
    "\n",
    "#max_date_overall_name = '2022-01-27'\n",
    "#max_date_overall = dateparser.parse(max_date_overall_name, settings={'TIMEZONE': 'America/Los_Angeles'}).date()\n",
    "\n",
    "#test_start_date_name = '2022-01-28'\n",
    "#test_start_date = dateparser.parse(test_start_date_name, settings={'TIMEZONE': 'America/Los_Angeles'}).date()\n",
    "\n",
    "#test_end_date_name = 'ten days ago'\n",
    "#test_end_date = dateparser.parse(test_end_date_name, settings={'TIMEZONE': 'America/Los_Angeles'}).date()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53aa316d-1b76-4b10-a9e4-f271be7d4373",
   "metadata": {},
   "source": [
    "LOOPA TEST!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "3e2f5c2d-52ec-4d2a-8eef-07cdfba6803d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign Start Row\n",
    "start_row = 0\n",
    "\n",
    "# Create empty DataFrame to combine data into\n",
    "all_search_analytics_df = pd.DataFrame()\n",
    "\n",
    "# Build Request Body\n",
    "\n",
    "sa_request = {\n",
    "            #'startDate': start_date,\n",
    "            #'endDate': end_date,\n",
    "            'startDate': start_date,\n",
    "            'endDate': end_date,\n",
    "            'dimensions': [\"date\",\"page\",\"device\",\"query\",\"country\"],\n",
    "            'rowLimit': 25000,\n",
    "            }\n",
    "\n",
    "site_url = \"https://advokatfamiljforsvar.se\"\n",
    "\n",
    "\n",
    "# Loop over requests until all rows are pulled into DataFrame\n",
    "while True:\n",
    "    sa_request['startRow'] = start_row\n",
    "    gsc_search_analytics = service.searchanalytics().query(siteUrl=site_url, body=sa_request).execute()\n",
    "\n",
    "    try:\n",
    "\n",
    "        all_search_analytics_df = pd.concat([all_search_analytics_df, pd.DataFrame(gsc_search_analytics['rows'])])\n",
    "    except KeyError:\n",
    "        break\n",
    "\n",
    "    if len(gsc_search_analytics['rows']) < 25000:\n",
    "        break\n",
    "\n",
    "    start_row += 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "3bd5daf7-772b-4d17-a9c1-2b0eb5ddaec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep copy\n",
    "df = all_search_analytics_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "9525048c-c55a-4244-b952-eb20b5e9531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['index'] = df.reset_index().index\n",
    "df.set_index('index',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "6754d45d-9e70-4c9e-a8c7-df013ca565f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new df from the column of lists\n",
    "df_split = pd.DataFrame(df['keys'].tolist(), columns=[\"date\",\"page\",\"device\",\"query\",\"country\"])\n",
    "# concat df and split_df\n",
    "df_split['index'] = df_split.reset_index().index\n",
    "df_split.set_index('index',inplace=True)\n",
    "\n",
    "df_concat = pd.concat([df, df_split], axis=1)\n",
    "# display df\n",
    "df = df_concat.drop('keys', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "a45a27ce-2735-43dc-90c3-86861cd9822b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df.iloc[:,-5:], df.iloc[:,0:-5]], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "a2dc591d-a1ea-4d8c-94c8-b51d49cb64bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "fd55d483-0ae1-476f-9c03-8d0b4eedb837",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dates_funcs.sortOut_date_searchFormat(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "9c1ddc79-1988-42e6-ae1c-07106fd66047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to case matching reference and analytics data\n",
    "df['device'] = df['device'].str.lower()\n",
    "df['country'] = df['country'].str.upper()\n",
    "            \n",
    "# Column names to matching reference and analytics data\n",
    "df.rename(columns = {'country':'countryIdLong', 'page':'landingPage', 'device':'deviceCategory'}, inplace = True)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "617cfae2-5ef7-4b04-baef-8132973320ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(324071, 16)\n"
     ]
    }
   ],
   "source": [
    "df = df.replace('', np.nan)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "5c3a2e91-5a5c-474d-acfc-323878abb682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split by years\n",
    "df_by_years = dates_funcs.split_years(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "ef37aa5a-88fa-4d7c-971c-291a29814e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_years_dc = df_by_years.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "a7ff21e1-70b0-469b-bdca-f79392a3e781",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "df_by_months = pd.DataFrame()\n",
    "\n",
    "for x in range(len(df_by_years_dc)):\n",
    "    df_by_months[x] = []\n",
    "\n",
    "for x in range(len(df_by_years_dc)):\n",
    "    df_by_months[x] = dates_funcs.split_months(df_by_years_dc[x])\n",
    "\n",
    "pd.options.mode.chained_assignment = 'warn' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "8e0bc079-0049-4e3d-aff9-a74b06ad40a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten df_by_months[x][y] (two levels) structure to array of dataframes (one level)\n",
    "dfs_array = df_by_months.to_numpy().flatten(order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "fda3bfae-4bd3-4395-85fa-48c8289ca508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched data until 2023-06-11\n",
      "Written to latestDate.txt\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    " ## Max time to latestDatefile\n",
    "    \n",
    "# Find largest date in dataframes, looking at df eventName, which should have all dates. (?)\n",
    "maxTimestamp = df[\"dateFull\"].max()\n",
    "maxTimestampString = datetime.datetime.strftime(maxTimestamp,'%Y-%m-%d')\n",
    "maxDate = datetime.datetime.strptime(maxTimestampString,'%Y-%m-%d').date()\n",
    "    \n",
    "print(\"Fetched data until \"+maxTimestampString)\n",
    "    \n",
    "    # If date is larger than priviously max date.\n",
    "if maxDate > maxSavedDateDT:\n",
    "    # Write largest date to file\n",
    "    f = open(\"latestDate.txt\", 'w')\n",
    "    f.write(maxTimestampString)\n",
    "    f.close()\n",
    "    \n",
    "print(\"Written to latestDate.txt\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "97d4f83a-40e4-49b4-a036-bfc7836ac940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all dataframes, select max year and month for naming.\n",
    "# Convert dataframes all datatypes to strings as well.\n",
    "fileNameList = []\n",
    "\n",
    "for x in range(len(dfs_array)):\n",
    "    dfs_array[x] = dfs_array[x].astype(str)\n",
    "    fileNameList.append(dfs_array[x]['year'].min()+'_'+dfs_array[x]['month'].min())\n",
    "\n",
    "# Convert list of datetime, to list of strings\n",
    "#fileNameList = [dts.strftime(\"%Y-%m-%d\") for dts in fileNameList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "99b3289a-b57e-48be-b56b-769a50487df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over all dataframes and write to file with filename of firstdate in df.\n",
    "for x, y in zip(range(len(dfs_array)),fileNameList):\n",
    "    dfs_array[x].to_csv(f'output/csv/search_console_from_{y}.csv',index=None,mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cdb8cd-3a80-42bf-b97e-83b8c5a1f77d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae28e3e4-d7be-4abc-809e-ea0d79ec605f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b1aab6-54ef-49e1-9648-1efeb8f93d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
